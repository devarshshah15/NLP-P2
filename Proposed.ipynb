{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPP2Propo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLxW3WqBq5ft",
        "outputId": "afea9495-de66-45f0-8486-7fa00b76d0ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import pandas as pd\n",
        "from nltk import word_tokenize\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oaBc533II3G"
      },
      "source": [
        "**Preprocessing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLlZIqdGrKYl"
      },
      "source": [
        "df=pd.read_csv(\"p2_train.csv\")\n",
        "df_test=pd.read_csv(\"p2_test.csv\")\n",
        "df_question=df[\"question\"]\n",
        "df_response=df[\"response\"]\n",
        "df_question_test=df_test[\"question\"]\n",
        "df_response_test=df_test[\"response\"]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVE9FX4poPkt"
      },
      "source": [
        "def preprocessor(text):\n",
        "  review=re.sub('\\[[^]]*\\]', ' ', str(text))\n",
        "  review=re.sub('[^a-zA-z]', ' ', str(text))\n",
        "  review=review.lower().split()\n",
        "  return review\n",
        "df_question=df_question.apply(preprocessor)\n",
        "df_response=df_response.apply(preprocessor)\n",
        "df_question_test=df_question_test.apply(preprocessor)\n",
        "df_response_test=df_response_test.apply(preprocessor)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmowL72AkalO"
      },
      "source": [
        "**POS Tagging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhlynwcgBR4Y"
      },
      "source": [
        "lst=[]\n",
        "for index, row in df_question.to_frame().iterrows():\n",
        "  for i in row:\n",
        "    string=\" \"\n",
        "    string=string.join(i)\n",
        "    tokens=word_tokenize(string)\n",
        "    lst.append(nltk.pos_tag(tokens))\n",
        "lst1=[]\n",
        "for index, row in df_response.to_frame().iterrows():\n",
        "  for i in row:\n",
        "    string=\" \"\n",
        "    string=string.join(i)\n",
        "    tokens=word_tokenize(string)\n",
        "    lst1.append(nltk.pos_tag(tokens))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpgqMJvoHbmM"
      },
      "source": [
        "lst_test=[]\n",
        "for index, row in df_question_test.to_frame().iterrows():\n",
        "  for i in row:\n",
        "    i=i[1:len(i)-1]\n",
        "    string=\" \"\n",
        "    string=string.join(i)\n",
        "    tokens=word_tokenize(string)\n",
        "    lst_test.append(nltk.pos_tag(tokens))\n",
        "lst1_test=[]\n",
        "for index, row in df_response_test.to_frame().iterrows():\n",
        "  for i in row:\n",
        "    i=i[1:len(i)-1]\n",
        "    string=\" \"\n",
        "    string=string.join(i)\n",
        "    tokens=word_tokenize(string)\n",
        "    lst1_test.append(nltk.pos_tag(tokens))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEJFg7WLIUbu"
      },
      "source": [
        "**Combining words with tags**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ9CalkG9sly"
      },
      "source": [
        "res=[]\n",
        "for i in lst:\n",
        "  combined_list=[]\n",
        "  for j in i:\n",
        "    combined_list.append(j[0]+\"/\"+j[1])\n",
        "  res.append(combined_list)\n",
        "res1=[]\n",
        "for i in lst1:\n",
        "  combined_list=[]\n",
        "  for j in i:\n",
        "    combined_list.append(j[0]+\"/\"+j[1])\n",
        "  res1.append(combined_list)\n",
        "res_test=[]\n",
        "for i in lst_test:\n",
        "  combined_list=[]\n",
        "  for j in i:\n",
        "    combined_list.append(j[0]+\"/\"+j[1])\n",
        "  res_test.append(combined_list)\n",
        "res1_test=[]\n",
        "for i in lst1_test:\n",
        "  combined_list=[]\n",
        "  for j in i:\n",
        "    combined_list.append(j[0]+\"/\"+j[1])\n",
        "  res1_test.append(combined_list)\n",
        "   "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9ll4Oi37Nx5",
        "outputId": "d181afee-6e7f-4c6c-b7eb-faf00d1d74d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180944 sha256=f1d760623604a52884b0c3e121d2f301cbb85a1c6d59d42d854ffc034d6b79f2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pv40by8n/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ0sdIny8Yhe"
      },
      "source": [
        "import spacy\n",
        "import en_core_web_lg\n",
        "nlp=en_core_web_lg.load()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KksepctRLKR"
      },
      "source": [
        "**Finding vectors using Spacy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYNBg6-Z7znw"
      },
      "source": [
        "def get_vector(x):\n",
        "    doc=nlp(x)\n",
        "    vec=doc.vector\n",
        "    return vec\n",
        "\n",
        "temp1,temp2=[],[]\n",
        "for i in res:\n",
        "    string=\" \"\n",
        "    string=string.join(i)\n",
        "    temp1.append(string)\n",
        "for i in res1:\n",
        "    string=\" \"\n",
        "    string=string.join(i)\n",
        "    temp2.append(string)\n",
        "question,response=pd.Series(temp1),pd.Series(temp2)\n",
        "question=question.apply(lambda x: get_vector(x))\n",
        "response=response.apply(lambda x: get_vector(x))\n",
        "question,response=question.to_numpy(),response.to_numpy()\n",
        "question,response=question.reshape(-1,1),response.reshape(-1,1)\n",
        "question=np.concatenate(np.concatenate(question,axis=0),axis=0).reshape(-1,300)\n",
        "response=np.concatenate(np.concatenate(response,axis=0),axis=0).reshape(-1,300)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Uy3tNl-hdG",
        "outputId": "e828dbe0-7b40-46aa-8047-d42c4329d81d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "final_vector=np.concatenate((question,response),axis=1)\n",
        "final_vector.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1640, 600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb-uojc_JbtY"
      },
      "source": [
        "temp1,temp2=[],[]\n",
        "for i in res_test:\n",
        "    string=\" \"\n",
        "    string=string.join(i)\n",
        "    temp1.append(string)\n",
        "for i in res1_test:\n",
        "    string=\" \"\n",
        "    string=string.join(i)\n",
        "    temp2.append(string)\n",
        "question,response=pd.Series(temp1),pd.Series(temp2)\n",
        "question=question.apply(lambda x: get_vector(x))\n",
        "response=response.apply(lambda x: get_vector(x))\n",
        "question,response=question.to_numpy(),response.to_numpy()\n",
        "question,response=question.reshape(-1,1),response.reshape(-1,1)\n",
        "question=np.concatenate(np.concatenate(question,axis=0),axis=0).reshape(-1,300)\n",
        "response=np.concatenate(np.concatenate(response,axis=0),axis=0).reshape(-1,300)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLFan0MFJkfH",
        "outputId": "b36d86b1-fe7f-4a2b-dc30-f03e4acc0d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "final_vector_test=np.concatenate((question,response),axis=1)\n",
        "final_vector_test.shape\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfiiZORTRP9V"
      },
      "source": [
        "**Classifiers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrwE_WUpJyqb"
      },
      "source": [
        "X_train,X_test,y_train,y_test=final_vector,final_vector_test,df[\"type\"],df_test[\"type\"]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft1WOxYWs6aP",
        "outputId": "a96f2788-ec27-478e-e2e4-324764a950df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=15, random_state=10,class_weight=\"balanced\")\n",
        "clf.fit(X_train,y_train)\n",
        "predictions=clf.predict(X_test)\n",
        "print(\"Accuracy is\",accuracy_score(predictions,y_test))\n",
        "print(\"F1 Score is\",f1_score(predictions,y_test,average='weighted'))\n",
        "print(\"Precision Score is\",precision_score(predictions,y_test,average=\"weighted\"))\n",
        "print(\"Recall Score is\",recall_score(predictions,y_test,average=\"weighted\"))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.7609756097560976\n",
            "F1 Score is 0.8219955654101998\n",
            "Precision Score is 0.9012382739212009\n",
            "Recall Score is 0.7609756097560976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8So7TVWRs88l",
        "outputId": "7e5bfdd0-7ce4-4e69-ca4a-ae77aad0d89f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(confusion_matrix(predictions,y_test, labels=[\"answered\", \"attacked\", \"irrelevant\",\"agreed\"]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[306  35  32  11]\n",
            " [  2   2   2   0]\n",
            " [ 12   1   4   2]\n",
            " [  0   1   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKMAMy995Drr"
      },
      "source": [
        "**Sentence Embeddings(Spacy)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3BLmdPf5QzR"
      },
      "source": [
        "que=[]\n",
        "for i in df_question:\n",
        "  que.append(i)\n",
        "resp=[]\n",
        "for i in df_response:\n",
        "  resp.append(i)\n",
        "que_test=[]\n",
        "for i in df_question_test:\n",
        "  que_test.append(i)\n",
        "resp_test=[]\n",
        "for i in df_response_test:\n",
        "  resp_test.append(i)\n",
        "  "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRHYDv63PuSy"
      },
      "source": [
        "def get_vector(x):\n",
        "    doc=nlp(x)\n",
        "    vec=doc.vector\n",
        "    return vec\n",
        "temp1,temp2=[],[]\n",
        "for i in que:\n",
        "    string=\" \"\n",
        "    string=string.join(i)\n",
        "    temp1.append(string)\n",
        "for i in resp:\n",
        "    string=\" \"\n",
        "    string=string.join(i)\n",
        "    temp2.append(string)\n",
        "question,response=pd.Series(temp1),pd.Series(temp2)\n",
        "question=question.apply(lambda x: get_vector(x))\n",
        "response=response.apply(lambda x: get_vector(x))\n",
        "question,response=question.to_numpy(),response.to_numpy()\n",
        "question,response=question.reshape(-1,1),response.reshape(-1,1)\n",
        "question_train=np.concatenate(np.concatenate(question,axis=0),axis=0).reshape(-1,300)\n",
        "response_train=np.concatenate(np.concatenate(response,axis=0),axis=0).reshape(-1,300)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HAojIZqRnTk",
        "outputId": "5de9dac8-6498-46d6-9303-bd308153962b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "final_vector_1=np.concatenate((question_train,response_train),axis=1)\n",
        "final_vector_1.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1640, 600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY8A8ooyP9EQ"
      },
      "source": [
        "temp1,temp2=[],[]\n",
        "for i in que_test:\n",
        "    string=\" \"\n",
        "    string=string.join(i)\n",
        "    temp1.append(string)\n",
        "for i in resp_test:\n",
        "    string=\" \"\n",
        "    string=string.join(i)\n",
        "    temp2.append(string)\n",
        "question,response=pd.Series(temp1),pd.Series(temp2)\n",
        "question=question.apply(lambda x: get_vector(x))\n",
        "response=response.apply(lambda x: get_vector(x))\n",
        "question,response=question.to_numpy(),response.to_numpy()\n",
        "question,response=question.reshape(-1,1),response.reshape(-1,1)\n",
        "question_test=np.concatenate(np.concatenate(question,axis=0),axis=0).reshape(-1,300)\n",
        "response_test=np.concatenate(np.concatenate(response,axis=0),axis=0).reshape(-1,300)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvNHiVNjRmyL",
        "outputId": "46c212e9-53e2-4844-a27c-7b82621464d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "final_vector_1_test=np.concatenate((question_test,response_test),axis=1)\n",
        "final_vector_1_test.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEUTR_mDRUjS"
      },
      "source": [
        "**PCA(Dimensionality Reduction)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng5PczX8AcRh",
        "outputId": "c7539921-109f-484e-dd54-36568bd5a217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pca_train=np.concatenate((final_vector,final_vector_1),axis=1)\n",
        "pca_train.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1640, 1200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPCibuAXA0cT",
        "outputId": "891692d3-9fb4-4024-bb28-0d8697b81582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pca_test=np.concatenate((final_vector_test,final_vector_1_test),axis=1)\n",
        "pca_test.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 1200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfZ27iOYBzq2"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "pca_train = scaler.fit_transform(pca_train)\n",
        "pca_test =scaler.fit_transform(pca_test)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUst3sIvA8Xd"
      },
      "source": [
        "pca = PCA(n_components=100)\n",
        "pca.fit(pca_train)\n",
        "a=pca.transform(pca_train)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jVB90qSCU2N"
      },
      "source": [
        "pca = PCA(n_components=100)\n",
        "pca.fit(pca_test)\n",
        "b=pca.transform(pca_test)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW7eiTYgCeDM"
      },
      "source": [
        "X_train,X_test,y_train,y_test=a,b,df[\"type\"],df_test[\"type\"]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mJUz2lbCjj3",
        "outputId": "3dd2c6df-d367-49bc-db59-66aaf670c705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=10, random_state=30,class_weight=\"balanced\")\n",
        "clf.fit(X_train,y_train)\n",
        "predictions=clf.predict(X_test)\n",
        "print(\"Accuracy is\",accuracy_score(predictions,y_test))\n",
        "print(\"F1 Score is\",f1_score(predictions,y_test,average='weighted'))\n",
        "print(\"Precision Score is\",precision_score(predictions,y_test,average=\"weighted\"))\n",
        "print(\"Recall Score is\",recall_score(predictions,y_test,average=\"weighted\"))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.7219512195121951\n",
            "F1 Score is 0.7838176638176639\n",
            "Precision Score is 0.8593669768934531\n",
            "Recall Score is 0.7219512195121951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BQt_6w0CnSi",
        "outputId": "2d55f871-db36-4f58-e70c-2e14b811087f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(confusion_matrix(y_test, predictions,labels=[\"answered\", \"attacked\", \"irrelevant\",\"agreed\"]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[295  18   6   1]\n",
            " [ 39   0   0   0]\n",
            " [ 35   2   1   0]\n",
            " [ 13   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_mWsJjg7S9e"
      },
      "source": [
        "**Cosine Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1cvDY977Okw",
        "outputId": "a72ab64a-7914-4a43-d26d-7005562ae57d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import math\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "WORD = re.compile(r\"\\w+\")\n",
        "\n",
        "\n",
        "def get_cosine(vec1, vec2):\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
        "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "\n",
        "def text_to_vector(text):\n",
        "    words = WORD.findall(text)\n",
        "    return Counter(words)\n",
        "\n",
        "\n",
        "cosi=[]\n",
        "for i in range(len(df)):\n",
        "  vector1 = text_to_vector(df.question[i])\n",
        "  vector2 = text_to_vector(df.response[i])\n",
        "  cosine = get_cosine(vector1, vector2)\n",
        "  cosi.append(cosine)\n",
        "print(len(cosi))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k49TL1_K7YjO"
      },
      "source": [
        "cosi=np.array(cosi)\n",
        "cosi = np.reshape(cosi,(1, cosi.size)).reshape(-1,1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mrl3uaJ7abb",
        "outputId": "9e5d8dc6-cd6b-4f5a-b264-429a4190dbee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import math\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "WORD = re.compile(r\"\\w+\")\n",
        "\n",
        "\n",
        "def get_cosine(vec1, vec2):\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
        "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "\n",
        "def text_to_vector(text):\n",
        "    words = WORD.findall(text)\n",
        "    return Counter(words)\n",
        "\n",
        "\n",
        "cosi_test=[]\n",
        "for i in range(len(df_test)):\n",
        "  vector1 = text_to_vector(df_test.question[i])\n",
        "  vector2 = text_to_vector(df_test.response[i])\n",
        "  cosine = get_cosine(vector1, vector2)\n",
        "  cosi_test.append(cosine)\n",
        "print(len(cosi_test))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "410\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxMFf8t77cS2"
      },
      "source": [
        "cosi_test=np.array(cosi_test)\n",
        "cosi_test=np.reshape(cosi_test,(1, cosi_test.size)).reshape(-1,1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxn3SPjq7fMy"
      },
      "source": [
        "X_train,X_test,y_train,y_test=cosi,cosi_test,df[\"type\"],df_test[\"type\"]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QTu1VCj-OVw",
        "outputId": "f35146ae-e57c-4897-ecf9-9bbaa98a5636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "clf=LinearSVC(class_weight=\"balanced\")\n",
        "clf.fit(X_train,y_train)\n",
        "predictions=clf.predict(X_test)\n",
        "print(\"Accuracy is\",accuracy_score(predictions,y_test))\n",
        "print(\"F1 Score is\",f1_score(predictions,y_test,average='weighted'))\n",
        "print(\"Precision Score is\",precision_score(predictions,y_test,average=\"weighted\"))\n",
        "print(\"Recall Score is\",recall_score(predictions,y_test,average=\"weighted\"))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.7073170731707317\n",
            "F1 Score is 0.7377316200526235\n",
            "Precision Score is 0.7789132702182285\n",
            "Recall Score is 0.7073170731707317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqkceBl3-UGD",
        "outputId": "dcd5db74-ee59-4beb-8ec1-1e59410d5380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(confusion_matrix(y_test, predictions,labels=[\"answered\", \"attacked\", \"irrelevant\",\"agreed\"]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[275   0  45   0]\n",
            " [ 35   0   4   0]\n",
            " [ 23   0  15   0]\n",
            " [  6   0   7   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz1FrV5ABkmb"
      },
      "source": [
        "**Sentiment Analysis**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La1_UTs-BpdG"
      },
      "source": [
        "analyzer = SentimentIntensityAnalyzer()\n",
        "temp=\" \"\n",
        "question = [analyzer.polarity_scores(temp.join(x))['compound'] for x in df_question]\n",
        "temp=\" \"\n",
        "response = [analyzer.polarity_scores(temp.join(x))['compound'] for x in df_response]\n",
        "question=pd.DataFrame(question)\n",
        "response=pd.DataFrame(response)\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-OhBu2SBrME"
      },
      "source": [
        "temp=\" \"\n",
        "question_test = [analyzer.polarity_scores(temp.join(x))['compound'] for x in df_question_test]\n",
        "temp=\" \"\n",
        "response_test = [analyzer.polarity_scores(temp.join(x))['compound'] for x in df_response_test]\n",
        "question_test=pd.DataFrame(question_test)\n",
        "response_test=pd.DataFrame(response_test)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geVbc_seCFoM"
      },
      "source": [
        "final_vector=np.concatenate((question,response),axis=1)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-4ALWhwCUqc"
      },
      "source": [
        "final_vector_test=np.concatenate((question_test,response_test),axis=1)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i6YaACmRkKY"
      },
      "source": [
        "**Set 2:Baseline+additional features(classification)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQSaWQwfSk6Z"
      },
      "source": [
        "train=np.concatenate((a,cosi,final_vector),axis=1)\n",
        "test=np.concatenate((b,cosi_test,final_vector_test),axis=1)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2YUiIC4Ccc0"
      },
      "source": [
        "X_train,X_test,y_train,y_test=train,test,df[\"type\"],df_test[\"type\"]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfPcvIgLDt-a",
        "outputId": "05160feb-0d63-4d6f-efc0-b6d9c8f99789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "clf=LinearSVC(class_weight=\"balanced\")\n",
        "clf.fit(X_train,y_train)\n",
        "predictions=clf.predict(X_test)\n",
        "print(\"Accuracy is\",accuracy_score(predictions,y_test))\n",
        "print(\"F1 Score is\",f1_score(predictions,y_test,average='weighted'))\n",
        "print(\"Precision Score is\",precision_score(predictions,y_test,average=\"weighted\"))\n",
        "print(\"Recall Score is\",recall_score(predictions,y_test,average=\"weighted\"))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.4878048780487805\n",
            "F1 Score is 0.43841280651110687\n",
            "Precision Score is 0.4031120395971166\n",
            "Recall Score is 0.4878048780487805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwtYxWKUD5Dh",
        "outputId": "a6e780b1-34e3-4552-faa1-9c0a5d65770d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(confusion_matrix(y_test, predictions,labels=[\"answered\", \"attacked\", \"irrelevant\",\"agreed\"]))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[194  54  58  14]\n",
            " [ 29   3   6   1]\n",
            " [ 26   6   3   3]\n",
            " [  6   3   4   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZEwv1VqS2TK",
        "outputId": "fedc558d-8eaa-435d-a212-4b6e518ffb27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=20, random_state=25,class_weight=\"balanced\")\n",
        "clf.fit(X_train,y_train)\n",
        "predictions=clf.predict(X_test)\n",
        "print(\"Accuracy is\",accuracy_score(predictions,y_test))\n",
        "print(\"F1 Score is\",f1_score(predictions,y_test,average='weighted'))\n",
        "print(\"Precision Score is\",precision_score(predictions,y_test,average=\"weighted\"))\n",
        "print(\"Recall Score is\",recall_score(predictions,y_test,average=\"weighted\"))\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.7536585365853659\n",
            "F1 Score is 0.8345953668741708\n",
            "Precision Score is 0.9350076219512194\n",
            "Recall Score is 0.7536585365853659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JSYp27LS6N_",
        "outputId": "3f06c534-0d4c-42d0-b959-0a9d10f10ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(confusion_matrix(y_test, predictions,labels=[\"answered\", \"attacked\", \"irrelevant\",\"agreed\"]))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[309   8   3   0]\n",
            " [ 39   0   0   0]\n",
            " [ 38   0   0   0]\n",
            " [ 11   0   2   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg1BzmCp_TeH",
        "outputId": "59e5fed0-9f4d-4cd9-c945-ff244bb23e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_final = pd.read_csv('p2_test.csv')\n",
        "df_final['predicted_type']=predictions\n",
        "df_final=df_final.rename(columns={\"label\": \"gold_type\"})\n",
        "df_final"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>thread_id</th>\n",
              "      <th>question_id</th>\n",
              "      <th>response_id</th>\n",
              "      <th>no_turn_q_id</th>\n",
              "      <th>quoted_q_id</th>\n",
              "      <th>precedent</th>\n",
              "      <th>question</th>\n",
              "      <th>subsequent</th>\n",
              "      <th>response</th>\n",
              "      <th>type</th>\n",
              "      <th>predicted_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>232fcl</td>\n",
              "      <td>232fcl</td>\n",
              "      <td>cgsrxd3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>q_27319</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Now if Julie was underage (let's say you and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\nNo. She's happy, he's happy, who am I to end...</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>221bir</td>\n",
              "      <td>cgikp7a</td>\n",
              "      <td>cginbgy</td>\n",
              "      <td>n_228942</td>\n",
              "      <td>q_28801</td>\n",
              "      <td>And Egypt...there was a lot of chaos, a lot of...</td>\n",
              "      <td>Did the protests motivate the military to act?</td>\n",
              "      <td>Undoubtedly. But it was still the military tha...</td>\n",
              "      <td>Seems a weird example to use in defence of an ...</td>\n",
              "      <td>attacked</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20s1x1</td>\n",
              "      <td>cg6ay9r</td>\n",
              "      <td>cg6f18i</td>\n",
              "      <td>n_244708</td>\n",
              "      <td>q_30570</td>\n",
              "      <td>&amp;gt; Hello! Both my major AND my minor are due...</td>\n",
              "      <td>Can you illustrate how a single class in CS w...</td>\n",
              "      <td>Your statement that way more happiness is ach...</td>\n",
              "      <td>Oh gods yes. First of all, most students aren'...</td>\n",
              "      <td>answered</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1zyf3k</td>\n",
              "      <td>cfzfpej</td>\n",
              "      <td>cfzg0hy</td>\n",
              "      <td>n_254761</td>\n",
              "      <td>q_31795</td>\n",
              "      <td>Oh, come on, now you're just trying to misunde...</td>\n",
              "      <td>Didn't I even say, that I am completely and 10...</td>\n",
              "      <td>Let me make it very clear: I am an universal ...</td>\n",
              "      <td>Sure, but you still obviously have some precon...</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1yfntu</td>\n",
              "      <td>cfka1pw</td>\n",
              "      <td>cfkar3s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>q_34113</td>\n",
              "      <td>NaN</td>\n",
              "      <td>However if we forget that debate for a minute...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I'd be willing to guess that this question is ...</td>\n",
              "      <td>attacked</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>2sr2st</td>\n",
              "      <td>cns3qwy</td>\n",
              "      <td>cns4t4s</td>\n",
              "      <td>n_632548</td>\n",
              "      <td>q_78351</td>\n",
              "      <td>So, just to be clear, if a woman refused to ha...</td>\n",
              "      <td>Am I getting this right?</td>\n",
              "      <td>But if it's just about the money, would you b...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>answered</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>38x7jw</td>\n",
              "      <td>38x7jw</td>\n",
              "      <td>crykb9x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>q_8321</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Further evidence that merely being overweight ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\n</td>\n",
              "      <td>irrelevant</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407</th>\n",
              "      <td>2ija3a</td>\n",
              "      <td>cl2zs70</td>\n",
              "      <td>cl33t6t</td>\n",
              "      <td>n_65173</td>\n",
              "      <td>q_8864</td>\n",
              "      <td>Why? Just because it's expected of us?</td>\n",
              "      <td>By who?</td>\n",
              "      <td>This is hardly ever a good reason for doing or...</td>\n",
              "      <td>Maybe I didn't phrase this first point well. B...</td>\n",
              "      <td>answered</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>2hqis0</td>\n",
              "      <td>ckve18f</td>\n",
              "      <td>ckvh0bt</td>\n",
              "      <td>n_70808</td>\n",
              "      <td>q_9521</td>\n",
              "      <td>&amp;gt; You don't have to but you should be able ...</td>\n",
              "      <td>Why are the consequences of everyone taking a...</td>\n",
              "      <td>If everyone became a dental hygienist we'd al...</td>\n",
              "      <td>It's worth considering the societal implicatio...</td>\n",
              "      <td>answered</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>409</th>\n",
              "      <td>2qoom3</td>\n",
              "      <td>cn89k72</td>\n",
              "      <td>cn8n79c</td>\n",
              "      <td>n_7489</td>\n",
              "      <td>q_997</td>\n",
              "      <td>\\n&amp;gt;This is all well and good but this has ...</td>\n",
              "      <td>Consider this: Who has the right to say &lt;&amp;quot...</td>\n",
              "      <td>I think it is fair to say that the owner of t...</td>\n",
              "      <td>Well, really no one. Beauty, I think, is subje...</td>\n",
              "      <td>answered</td>\n",
              "      <td>answered</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>410 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    thread_id question_id  ...        type predicted_type\n",
              "0      232fcl      232fcl  ...  irrelevant       answered\n",
              "1      221bir     cgikp7a  ...    attacked       answered\n",
              "2      20s1x1     cg6ay9r  ...    answered       answered\n",
              "3      1zyf3k     cfzfpej  ...  irrelevant       answered\n",
              "4      1yfntu     cfka1pw  ...    attacked       answered\n",
              "..        ...         ...  ...         ...            ...\n",
              "405    2sr2st     cns3qwy  ...    answered       answered\n",
              "406    38x7jw      38x7jw  ...  irrelevant       answered\n",
              "407    2ija3a     cl2zs70  ...    answered     irrelevant\n",
              "408    2hqis0     ckve18f  ...    answered       answered\n",
              "409    2qoom3     cn89k72  ...    answered       answered\n",
              "\n",
              "[410 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNAFXSH9_Z4S"
      },
      "source": [
        "df_final.to_csv('test_output_proposedsolution.csv')\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfO1L5PR_cgx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}